{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Géométrie et espace de formes - TP3 - Construction d'atlas et attaches aux données géométriques\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exemples d'appariements difféomorphiques : points, mesures, varifolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Codes pour l'implémentation LDDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "\n",
    "# packages optionnels:\n",
    "\n",
    "# KeOps library for kernel convolutions -- useless for small datasets\n",
    "#!pip install pykeops \n",
    "use_keops = False # use of \n",
    "\n",
    "# pyvista for displaying 3D graphics\n",
    "#!pip install 'pyvista[all]'\n",
    "use_pyvista = False\n",
    "\n",
    "# geomloss for optimal transport loss functions\n",
    "#!pip install geomloss\n",
    "\n",
    "\n",
    "if use_keops:\n",
    "    from pykeops.torch import LazyTensor\n",
    "\n",
    "########################\n",
    "### fonctions noyaux ###\n",
    "########################\n",
    "\n",
    "# noyau gaussien (K(x,y)b)_i = sum_j exp(-|xi-yj|^2/sigma^2)bj\n",
    "def GaussKernel(sigma):\n",
    "    oos2 = 1/sigma**2\n",
    "    def K(x,y,b):\n",
    "        x,y = x[:,None,:],y[None,:,:]\n",
    "        if use_keops:\n",
    "            x,y = LazyTensor(x),LazyTensor(y)\n",
    "        return (-oos2*((x-y)**2).sum(dim=2)).exp()@b\n",
    "    return K\n",
    "\n",
    "# noyau de Cauchy (K(x,y)b)_i = sum_j (1/(1+|xi-yj|^2/sigma^2))bj\n",
    "def CauchyKernel(sigma):\n",
    "    oos2 = 1/sigma**2\n",
    "    def K(x,y,b):\n",
    "        return (1/(1+oos2*torch.sum((x[:,None,:]-y[None,:,:])**2,dim=2)))@b\n",
    "    return K\n",
    "\n",
    "# noyau somme de noyaux\n",
    "def SumKernel(*kernels):\n",
    "    def K(*args):\n",
    "        return sum(k(*args) for k in kernels)\n",
    "    return K\n",
    "\n",
    "# noyau pour les varifolds (K(x,y,u,v)b)_i = sum_j exp(-|xi-yj|^2) <ui,vj>^2 bj\n",
    "def GaussLinKernel(sigma,lib=\"keops\"):\n",
    "    oos2 = 1/sigma**2\n",
    "    def K(x,y,u,v,b):\n",
    "        Kxy = torch.exp(-oos2*torch.sum((x[:,None,:]-y[None,:,:])**2,dim=2))\n",
    "        Sxy = torch.sum(u[:,None,:]*v[None,:,:],dim=2)**2\n",
    "        return (Kxy*Sxy)@b\n",
    "    return K\n",
    "\n",
    "###################################\n",
    "### solveur d'ODE et optimiseur ###\n",
    "###################################\n",
    "\n",
    "# solveur d'ODE\n",
    "def RalstonIntegrator(nt=10):\n",
    "    def f(ODESystem,x0,deltat=1.0):\n",
    "        x = tuple(map(lambda x:x.clone(),x0))\n",
    "        dt = deltat/nt\n",
    "        for i in range(nt):\n",
    "            xdot = ODESystem(*x)\n",
    "            xi = tuple(map(lambda x,xdot:x+(2*dt/3)*xdot,x,xdot))\n",
    "            xdoti = ODESystem(*xi)\n",
    "            x = tuple(map(lambda x,xdot,xdoti:x+(.25*dt)*(xdot+3*xdoti),x,xdot,xdoti))\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "# méthode d'optimisation générique\n",
    "def Optimize(loss,args,niter=5):\n",
    "    optimizer = torch.optim.LBFGS(args)\n",
    "    print('performing optimization...')\n",
    "    for i in range(niter):\n",
    "        print(\"iteration \",i+1,\"/\",niter)\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            L = loss(*args)\n",
    "            L.backward()\n",
    "            return L\n",
    "        optimizer.step(closure)\n",
    "    print(\"Done.\")\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "### implémentation LDDMM ###\n",
    "############################\n",
    "\n",
    "# définition du Hamiltonien H(p,q)\n",
    "def Hamiltonian(K):\n",
    "    def H(p,q):\n",
    "        return .5*(p*K(q,q,p)).sum()\n",
    "    return H\n",
    "\n",
    "# système hamiltonien à résoudre pour le shooting\n",
    "def HamiltonianSystem(K):\n",
    "    H = Hamiltonian(K)\n",
    "    def HS(p,q):\n",
    "        Gp,Gq = grad(H(p,q),(p,q), create_graph=True)\n",
    "        return -Gq,Gp\n",
    "    return HS\n",
    "\n",
    "# shooting = intégration du système hamiltonien\n",
    "def Shooting(p0,q0,K,deltat=1.0,Integrator=RalstonIntegrator()):\n",
    "    return Integrator(HamiltonianSystem(K),(p0,q0),deltat)\n",
    "\n",
    "# intégration des équations de flot\n",
    "def Flow(x0,p0,q0,K,deltat=1.0,Integrator=RalstonIntegrator()):\n",
    "    HS = HamiltonianSystem(K)\n",
    "    def FlowEq(x,p,q):\n",
    "        return (K(x,q,p),)+HS(p,q)\n",
    "    return Integrator(FlowEq,(x0,p0,q0),deltat)[0]\n",
    "\n",
    "# définition de la fonctionnelle à minimiser\n",
    "def LDDMMloss(q0,K,dataloss,gamma=0.):\n",
    "    def loss(p0):\n",
    "        p,q = Shooting(p0,q0,K)\n",
    "        return gamma * Hamiltonian(K)(p0,q0) + dataloss(q)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "### Fonctions d'attaches aux données ###\n",
    "########################################\n",
    "\n",
    "# fonction d'attache aux données pour des landmarks\n",
    "def losslmk(z):\n",
    "    def loss(q):\n",
    "        return ((q-z)**2).sum()\n",
    "    return loss\n",
    "\n",
    "# fonction d'attache aux données pour des nuages de points via le modèle des mesures\n",
    "def lossmeas(z,Kw):\n",
    "    nz = z.shape[0]\n",
    "    wz = torch.ones(nz,1)\n",
    "    cst = (1/nz**2)*Kw(z,z,wz).sum()\n",
    "    def loss(q):\n",
    "        nq = q.shape[0]\n",
    "        wq = torch.ones(nq,1)\n",
    "        return cst + (1/nq**2)*Kw(q,q,wq).sum() + (-2/(nq*nz))*Kw(q,z,wz).sum()\n",
    "    return loss\n",
    "\n",
    "# fonction d'attache aux données pour des nuages de points via le transport optimal régularisé\n",
    "# (nécessite le package geomloss)\n",
    "def loss_OT(z):\n",
    "    from geomloss import SamplesLoss\n",
    "    loss_ = SamplesLoss()\n",
    "    nz = z.shape[0]\n",
    "    wz = torch.ones(nz,1)\n",
    "    def loss(q):\n",
    "        nq = q.shape[0]\n",
    "        wq = torch.ones(nq,1)\n",
    "        return loss_(wq,q,wz,z)\n",
    "    return loss\n",
    "    \n",
    "# fonction d'attache aux données pour les surfaces triangulées, modèle des varifolds\n",
    "def lossVarifoldSurf(FS,VT,FT,K):\n",
    "    # VT: coordonnées des points de la surface cible\n",
    "    # FS,FT : indices des triangles des surfaces source et cible\n",
    "    # K : noyau varifold\n",
    "    def CompCLNn(F,V):\n",
    "        V0, V1, V2 = V.index_select(0,F[:,0]), V.index_select(0,F[:,1]), V.index_select(0,F[:,2])\n",
    "        C, N = .5*(V0+V1+V2), .5*torch.cross(V1-V0,V2-V0)\n",
    "        L = (N**2).sum(dim=1)[:,None].sqrt()\n",
    "        return C,L,N/L\n",
    "    CT,LT,NTn = CompCLNn(FT,VT)\n",
    "    cst = (LT*K(CT,CT,NTn,NTn,LT)).sum()\n",
    "    def loss(VS):\n",
    "        CS,LS,NSn = CompCLNn(FS,VS)\n",
    "        return cst + (LS*K(CS,CS,NSn,NSn,LS)).sum() - 2*(LS*K(CS,CT,NSn,NTn,LT)).sum()\n",
    "    return loss\n",
    "\n",
    "# fonction d'attache aux données pour les courbes, modèle des varifolds\n",
    "def lossVarifoldCurve(FS, VT, FT, K):\n",
    "    def get_center_length_tangents(F, V):\n",
    "        V0, V1 = V.index_select(0, F[:, 0]), V.index_select(0, F[:, 1])\n",
    "        centers, tangents = .5*(V0+V1), V1-V0\n",
    "        length = (tangents**2).sum(dim=1)[:, None].sqrt()\n",
    "        return centers, length, tangents / length\n",
    "    CT, LT, TTn = get_center_length_tangents(FT, VT)\n",
    "    cst = (LT * K(CT, CT, TTn, TTn, LT)).sum()\n",
    "    def loss(VS):\n",
    "        CS, LS, TSn = get_center_length_tangents(FS, VS)\n",
    "        return cst + (LS * K(CS, CS, TSn, TSn, LS)).sum() - 2 * (LS * K(CS, CT, TSn, TTn, LT)).sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "### fonctions d'affichage graphique ###\n",
    "#######################################\n",
    "\n",
    "# fonction d'affichage du résultat pour des données landmarks ou nuages de points\n",
    "def PlotRes2D(z, pts=None):\n",
    "    def plotfun(q0,p0,Kv, showgrid=True):\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        q0np, qnp, znp = q0.data.numpy(), q.data.numpy(), z.data.numpy()\n",
    "        plt.plot(znp[:,0],znp[:,1],'.');\n",
    "        plt.plot(q0np[:,0],q0np[:,1],'+');\n",
    "        plt.plot(qnp[:,0],qnp[:,1],'o');\n",
    "        plt.axis('equal');\n",
    "        if showgrid:\n",
    "            X = get_def_grid(p0,q0,Kv)\n",
    "            plt.plot(X[0],X[1],'k',linewidth=.25);\n",
    "            plt.plot(X[0].T,X[1].T,'k',linewidth=.25); \n",
    "        n,d = q0.shape\n",
    "        nt = 20\n",
    "        Q = np.zeros((n,d,nt))\n",
    "        for i in range(nt):\n",
    "            t = i/(nt-1)\n",
    "            Q[:,:,i] = Shooting(t*p0,q0,Kv)[1].data.numpy()\n",
    "        plt.plot(Q[:,0,:].T,Q[:,1,:].T,'y');\n",
    "        if type(pts)!=type(None):\n",
    "            phipts = Flow(pts,p0,q0,Kv).data\n",
    "            plt.plot(phipts.numpy()[:,0],phipts.numpy()[:,1],'.b',markersize=.1);\n",
    "    return plotfun\n",
    "\n",
    "# fonction d'affichage pour des données de type surface triangulée\n",
    "def PlotRes3D(VS,FS,VT,FT):\n",
    "    def plotfun(q0,p0,Kv, showgrid=True):\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        FSnp,VTnp, FTnp = FS.data.numpy(),  VT.data.numpy(), FT.data.numpy() \n",
    "        if use_pyvista:\n",
    "            import pyvista as pv\n",
    "            p = pv.Plotter()\n",
    "            opacity = 1\n",
    "            p.add_mesh(surf_to_pv(q0np,FSnp), color='lightblue', opacity=opacity)\n",
    "            p.add_mesh(surf_to_pv(qnp,FSnp), color='lightcoral', opacity=opacity)\n",
    "            p.add_mesh(surf_to_pv(VTnp,FTnp), color='lightgreen', opacity=opacity)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            p.add_mesh(lines_from_points(X[:,i,j,:].T))\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            p.show()\n",
    "        else:\n",
    "            fig = plt.figure();\n",
    "            plt.axis('off')\n",
    "            plt.title('LDDMM matching example')     \n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            ax.plot_trisurf(q0np[:,0],q0np[:,1],q0np[:,2],triangles=FSnp,alpha=.5)\n",
    "            ax.plot_trisurf(qnp[:,0],qnp[:,1],qnp[:,2],triangles=FSnp,alpha=.5)\n",
    "            ax.plot_trisurf(VTnp[:,0],VTnp[:,1],VTnp[:,2],triangles=FTnp,alpha=.5)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            ax.plot(X[0,i,j,:],X[1,i,j,:],X[2,i,j,:],'k',linewidth=.25);\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            fig.add_axes(ax)\n",
    "    return plotfun\n",
    "\n",
    "def get_def_grid(p0,q0,Kv,ng=50):\n",
    "    d = p0.shape[1]\n",
    "    p,q = Shooting(p0,q0,Kv)\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    a = list(np.min(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    b = list(np.max(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    sz = 0.2\n",
    "    lsp = list(np.linspace(a[k]-sz*(b[k]-a[k]),b[k]+sz*(b[k]-a[k]),ng,dtype=np.float32) for k in range(d))\n",
    "    X = np.meshgrid(*lsp)\n",
    "    x = np.concatenate(list(X[k].reshape(ng**d,1) for k in range(d)),axis=1)\n",
    "    phix = Flow(torch.from_numpy(x),p0,q0,Kv).detach().numpy()\n",
    "    X = phix.transpose().reshape([d]+[ng]*d)\n",
    "    return X\n",
    "\n",
    "\n",
    "def lines_from_points(points):\n",
    "    import pyvista as pv\n",
    "    \"\"\"Given an array of points, make a line set\"\"\"\n",
    "    poly = pv.PolyData()\n",
    "    poly.points = points\n",
    "    cells = np.full((len(points) - 1, 3), 2, dtype=np.int_)\n",
    "    cells[:, 1] = np.arange(0, len(points) - 1, dtype=np.int_)\n",
    "    cells[:, 2] = np.arange(1, len(points), dtype=np.int_)\n",
    "    poly.lines = cells\n",
    "    return poly\n",
    "\n",
    "def surf_to_pv(V,F):\n",
    "    import pyvista as pv\n",
    "    nf = F.shape[0]\n",
    "    F = np.hstack((np.ones((nf,1),dtype=\"int\")*3,F))\n",
    "    F = F.flatten()\n",
    "    surf = pv.PolyData(V,F)\n",
    "    return surf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de matching de landmarks - données \"poissons\" du TP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge les données\n",
    "pts1, pts2, lmk1, lmk2 = torch.load('fish.pt')\n",
    "\n",
    "# définition des points q0 = landmarks du premier poisson\n",
    "q0 = lmk1.clone().detach().requires_grad_(True)\n",
    "\n",
    "# définition du noyau Kv\n",
    "Kv = GaussKernel(sigma=.25)\n",
    "#Kv = CauchyKernel(sigma=.25)\n",
    "#Kv = SumKernel(CauchyKernel(sigma=.5), CauchyKernel(sigma=.25), CauchyKernel(sigma=.125))\n",
    "\n",
    "# terme d'attache aux données\n",
    "Dataloss = losslmk(lmk2)\n",
    "\n",
    "# fonction globale à minimiser\n",
    "loss = LDDMMloss(q0,Kv,Dataloss)\n",
    "\n",
    "# initialisation des vecteurs moments p0\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "\n",
    "# optimisation de p0\n",
    "p0, = Optimize(loss,[p0])\n",
    "\n",
    "# affichage du résultat\n",
    "PlotRes2D(lmk2,pts1)(q0,p0,Kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de matching de nuages de points / courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VS, FS, VT, FT = torch.load('curves.pt')\n",
    "q0 = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=.5)\n",
    "\n",
    "Dataloss = lossmeas(VT,GaussKernel(sigma=.5))\n",
    "#Dataloss = loss_OT(VT)\n",
    "#Dataloss = lossVarifoldCurve(FS, VT, FT, GaussLinKernel(sigma=.5))\n",
    "\n",
    "loss = LDDMMloss(q0,Kv,Dataloss)\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "p0, = Optimize(loss,[p0])\n",
    "\n",
    "# affichage du résultat\n",
    "PlotRes2D(VT)(q0,p0,Kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de matching de surfaces - modèle des varifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VS,FS,VT,FT = torch.load('hippos_reduc_reduc.pt') # ou 'hippos_reduc.pt' pour une surface moins simplifiée\n",
    "q0 = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=20)\n",
    "Dataloss = lossVarifoldSurf(FS,VT,FT,GaussLinKernel(sigma=20))\n",
    "loss = LDDMMloss(q0,Kv,Dataloss)\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "p0, = Optimize(loss,[p0])\n",
    "\n",
    "# affichage du résultat\n",
    "PlotRes3D(VS,FS,VT,FT)(q0,p0,Kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 1. Mise en évidence de la courbure de l'espace de formes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Question 1__ : On va construire ici un triangle dans l'espace des landmarks et le comparer à un triangle euclidien.\n",
    "Choisir trois configurations de points simples dans le plan, et calculer les appariements deux à deux pour une métrique LDDMM fixée.\n",
    "Calculer les longueurs des côtés du triangles (distances géodésiques entre les points), \n",
    "ainsi que les angles aux sommets à l'aide de la métrique locale. Comparer avec les valeurs qu'on obtiendrait dans le cas d'un triangle euclidien.\n",
    "Montrer que si la taille du noyau $\\sigma$ tend vers 0, on se rapproche de la situation euclidienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\x}{{\\bf x}}$\n",
    "$\\newcommand{\\p}{\\boldsymbol{p}}$\n",
    "$\\newcommand{\\q}{\\boldsymbol{q}}$\n",
    "$\\newcommand{\\id}{{\\mathrm{id}}}$\n",
    "$\\def\\scal#1#2{\\left\\langle #1\\mathbin{,}#2\\right\\rangle}$\n",
    "$\\newcommand{\\KV}{K_V}$\n",
    "$\\newcommand{\\z}{\\boldsymbol{z}}$\n",
    "\n",
    "## 2. Construction d'atlas\n",
    "\n",
    "Nous allons voir ici comment réaliser un modèle de construction d'atlas pour l'étude d'une population de formes. Autrement dit, à partir de la donnée de $N$ formes similaires $x^k$, nous cherchons à obtenir conjointement une forme moyenne (le prototype) $\\bar x$ et des déformations optimales $\\phi^k$ entre $\\bar x$ et $x^k$. La donnée finale des $N$ transformations $\\phi^k$ permet alors d'effectuer une étude statistique sur la population.\n",
    "\n",
    "Nous supposerons que les formes considérées sont paramétrables par des ensembles de points: $\\x^k=(x_i^k)_{1\\leq i\\leq n_k}\\in(\\R^d)^{n_k}$.\n",
    "\n",
    "### a) Premier modèle : déformations paramétrées par les points du prototype\n",
    "\n",
    "Nous considérons d'abord  la fonctionnelle suivante:\n",
    "$$\\tilde J(\\{\\phi^k\\}_{1\\leq k\\leq N},\\bar\\x)=\\sum_{k=1}^N\\left\\{\\gamma d_V(\\id,\\phi^k)^2+A_k(\\phi^k(\\bar \\x))\\right\\},$$\n",
    "où $V$ est un espace de Hilbert de champs de vecteurs, \n",
    "$$d_V(\\id,\\phi^k)^2=\\inf\\left\\{\\int_0^1\\|v(t,\\cdot)\\|_V^2\\;dt,\\;\\;\\phi^v(1,\\cdot)=\\phi^k\\right\\}$$\n",
    "avec $\\phi^v$ le flot des champs $v(t,\\cdot)$,\n",
    "$\\gamma>0$ un paramètre,\n",
    "et $A_k$ est la fonctionnelle d'attache aux données pour la forme $\\x^k$, tandis que $\\bar x$ est la \"forme\" (ensemble de points ici) prototype à optimiser. Le nombre de points $n$ de $\\bar x$ est fixé.\n",
    "Pour un tel problème, comme pour le problème d'appariement simple, les transformations optimales $\\phi^k$ sont paramétrées par des vecteurs $p_i(0)^k$ (appelés moments initiaux) attachés aux points $\\bar x_i$, et le problème revient à minimiser\n",
    "$$J(\\{\\p^k(0)\\}_{1\\leq k\\leq N},\\bar\\x)=\\sum_{k=1}^N\\left\\{\\gamma\\scal{\\p^k(0)}{\\KV(\\bar\\x,\\bar\\x)\\p^k(0)}+A_k(\\q^k(1))\\right\\},$$\n",
    "où $\\p^k(t),\\q^k(t)$ suivent les équations géodésiques (cf 2e TP), avec $\\q^k(0)=\\bar\\x$.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Question 2__ : On va travailler avec des données de types courbes 2D et utiliser l'attache aux données avec la méthode des varifolds : $A_k(\\z)=\\|[\\z]-[\\x^k]\\|_{W'}^2$, où $[\\z]$ désigne le varifold associé à la courbe échantillonnée par les points de $\\z$, et $\\|\\cdot\\|_{W'}$ la norme de Hilbert duale sur l'espace des varifolds. (N.B. Il n'est pas nécessaire de comprendre le modèle des varifolds pour réaliser ce qui suit ; on peut utiliser cette attache aux données directement)\n",
    "\n",
    "Adapter le code exemple d'appariement difféomorphique pour obtenir ce modèle de construction d'atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "def AtlasLDDMMloss(K,dataloss,gamma=0):\n",
    "    # fonction similaire à LDDMMloss, pour la construction d'atlas\n",
    "    # -> doit définir la fonction J(p^k,xbar) du TP\n",
    "    # arguments : \n",
    "    #    K : noyau KV du modèle difféomorphique\n",
    "    #    dataloss : liste ou t-uple de fonctions d'attache aux données\n",
    "    #    gamma : paramètre gamma de la fonction J\n",
    "    # sortie :\n",
    "    #    loss : fonction définissant J et pouvant être appelée sous la forme\n",
    "    #           loss(p^1,p^2,...,p^N,xbar)\n",
    "    #\n",
    "    # ... to do ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Question 3__ : Le fichier\n",
    "${\\it synth\\_20.pt}$ contient une liste ${\\sf x}$ de $20$ configurations de $n=44$ points dans le plan. Afficher ces configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 : affichage des données synth_20\n",
    "plt.figure(figsize=(16,20))\n",
    "x = torch.load('synth_20.pt')\n",
    "N = len(x) # N=20\n",
    "for k in range(N):\n",
    "    plt.subplot(5,4,k+1)\n",
    "    plt.plot(x[k][:,0],x[k][:,1])\n",
    "    plt.axis([0,1,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Question 4__ : Tester la méthode de construction d'atlas avec ces données, puis\n",
    "afficher les positions des points $x_i^k$, $\\bar x_i$ et $\\phi^k(\\bar x_i)$ après minimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des points xbar\n",
    "xbar = x[0].clone().detach().requires_grad_(True)\n",
    "\n",
    "nxbar = x[0].shape[0]\n",
    "FS = torch.tensor(np.array([np.arange(nxbar-1),np.arange(1,nxbar)]).T).contiguous()\n",
    "\n",
    "# définition du noyau Kv\n",
    "Kv = GaussKernel(sigma=.25)\n",
    "\n",
    "# définition du noyau Kw\n",
    "Kw = GaussLinKernel(sigma=.25)\n",
    "\n",
    "# terme d'attache aux données\n",
    "Dataloss = []\n",
    "for k in range(N):\n",
    "    VT = x[k]\n",
    "    nk = VT.shape[0]\n",
    "    FT = torch.tensor(np.array([np.arange(nk-1),np.arange(1,nk)]).T).contiguous()\n",
    "    loss = lossVarifoldCurve(FS, VT, FT, Kw)\n",
    "    Dataloss.append(loss)\n",
    "\n",
    "# fonction globale à minimiser\n",
    "loss = AtlasLDDMMloss(Kv,Dataloss, gamma=0.1)\n",
    "\n",
    "# initialisation des vecteurs moments p0\n",
    "p0 = []\n",
    "for k in range(N):\n",
    "    p0.append(torch.zeros(x[0].shape, requires_grad=True))\n",
    "\n",
    "# optimisation de p0 et xbar\n",
    "res = Optimize(loss,[*p0,xbar])\n",
    "p0 = res[:-1]\n",
    "xbar = res[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des résultats :\n",
    "\n",
    "print(\"affichage pour chaque observation des 3 courbes :\")\n",
    "print(\"prototype (bleu), déformation du prototype (rouge), et observation (noir pointillé)\")\n",
    "N = len(x) # N=20\n",
    "plt.figure(figsize=(20,4))\n",
    "for k in range(N):\n",
    "    plt.subplot(2,10,k+1)\n",
    "    plt.plot(xbar.detach()[:,0],xbar.detach()[:,1],\"b\")\n",
    "    p,q = Shooting(p0[k],xbar,Kv)\n",
    "    plt.plot(q.detach()[:,0],q.detach()[:,1],\"r\")\n",
    "    plt.plot(x[k][:,0],x[k][:,1],\"k:\")\n",
    "    plt.axis([0,1,0,1])\n",
    "\n",
    "print(\"affichage pour les 4 premières observations,\")\n",
    "print(\"du résultat du matching, avec trajectoires des points de contrôle et déformation de la grille\")\n",
    "plt.figure()\n",
    "for k in range(4):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    plt.plot(x[k][:,0],x[k][:,1])\n",
    "    plotfun = PlotRes2D(x[k])\n",
    "    plotfun(xbar,p0[k],Kv)\n",
    "    plt.axis([0,1,0,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5__ : A partir des vecteurs $\\p^k(0)$, réaliser une Analyse en Composantes Principales (utiliser la fonction ${\\sf PCA}$ fournie) afin d'extraire les directions principales de déformation de la population. Afficher les formes correspondant à la moyenne et aux deux premières directions principales de déformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "\n",
    "from numpy import mean,cov,cumsum,dot,linalg,size,flipud,argsort\n",
    "\n",
    "def PCA(X,numpc=0):\n",
    "    # perform Principal Component Analysis of data matrix X\n",
    "    # computing eigenvalues and eigenvectors of covariance matrix\n",
    "    M = (X-mean(X.T,axis=1)).T # subtract the mean (along columns)\n",
    "    [latent,coeff] = linalg.eig(cov(M))\n",
    "    p = size(coeff,axis=1)\n",
    "    idx = argsort(latent) # sorting the eigenvalues\n",
    "    idx = idx[::-1]       # in ascending order\n",
    "    # sorting eigenvectors according to the sorted eigenvalues\n",
    "    coeff = coeff[:,idx]\n",
    "    latent = latent[idx] # sorting eigenvalues\n",
    "    if numpc < p and numpc >= 0:\n",
    "        coeff = coeff[:,range(numpc)] # cutting some PCs if needed\n",
    "    score = dot(coeff.T,M) # projection of the data in the new space\n",
    "    return coeff,score,latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = p0[0].shape\n",
    "N = len(p0)\n",
    "X = np.zeros((N,n*d))\n",
    "for k in range(N):\n",
    "    X[k,:] = p0[k].detach().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff,score,latent = PCA(X,numpc=N)\n",
    "coeff = np.real(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6__ : Calculer les $C(i,k)$ pour $1\\leq i\\leq N$ et $1\\leq k\\leq 3$ correspondant aux coordonnées des données projetées sur les trois premiers axes principaux, puis visualiser la population de formes dans ces coordonnées projetées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp, ndisp = 3, 5\n",
    "p0_bar = mean(X,axis=0)\n",
    "k = 1\n",
    "for pca_index in range(ncomp):\n",
    "    sigma_pca = np.sqrt(np.real(latent[pca_index]))\n",
    "    for alpha in np.linspace(-2*sigma_pca, 2*sigma_pca, ndisp):\n",
    "        p0_mode = p0_bar + alpha * coeff[:,pca_index]\n",
    "        p0_mode = torch.tensor(p0_mode.reshape(n,d).astype(\"float32\"), requires_grad=True)\n",
    "        p,q = Shooting(p0_mode,xbar,Kv)\n",
    "        plt.subplot(ncomp,ndisp,k)        \n",
    "        plt.plot(q.detach()[:,0],q.detach()[:,1],\"*r\")\n",
    "        plt.axis([0,1,0,1])\n",
    "        k += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Deuxième modèle : dissociation des points de contrôle et du prototype\n",
    "\n",
    "$\\newcommand{\\bcc}{{\\bf c}}$\n",
    "A présent on introduit des variables supplémentaires $(c_i)_{1\\leq i\\leq n_c}$ \n",
    "correspondant aux points de contrôle des déformations $\\phi^k$, supposées dissociées des points du prototype. Les déformations $\\phi^k$ sont alors paramétrées par ces points et les vecteurs $(p^k_i(0))_{1\\leq i\\leq n_c}$:\n",
    "et le problème consiste alors à minimiser\n",
    "$$J(\\{\\p^k(0)\\}_{1\\leq k\\leq N},\\bar\\x,\\bcc)=\\sum_{k=1}^N\\left\\{\\gamma\\scal{\\p^k(0)}{\\KV(\\bcc,\\bcc)\\p^k(0)}+A_k(\\phi^k(\\bar\\x)\\right\\}.$$\n",
    "\n",
    "__Question 6__ : Ecrire les fonctions permettant de calculer la fonctionnelle.\n",
    "Faire des essais avec les données précédentes, avec par exemple $n_c=3$. Afficher la forme prototype optimale ainsi que les positions des points de contrôle $c_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AtlasLDDMMloss2(K,dataloss,gamma=0):\n",
    "    # fonction similaire à LDDMMloss, pour la construction d'atlas\n",
    "    # -> doit définir la fonction J(p^k,xbar) du TP\n",
    "    # arguments : \n",
    "    #    K : noyau KV du modèle difféomorphique\n",
    "    #    dataloss : liste ou t-uple de fonctions d'attache aux données\n",
    "    #    gamma : paramètre gamma de la fonction J\n",
    "    # sortie :\n",
    "    #    loss : fonction définissant J et pouvant être appelée sous la forme\n",
    "    #           loss(p^1,p^2,...,p^N,xbar)\n",
    "    #\n",
    "    # ... to do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des points xbar\n",
    "xbar = x[0].clone().detach().requires_grad_(True)\n",
    "\n",
    "nxbar = x[0].shape[0]\n",
    "FS = torch.tensor(np.array([np.arange(nxbar-1),np.arange(1,nxbar)]).T).contiguous()\n",
    "\n",
    "# définition du noyau Kv\n",
    "Kv = GaussKernel(sigma=.25)\n",
    "\n",
    "# définition du noyau Kw\n",
    "Kw = GaussLinKernel(sigma=.25)\n",
    "\n",
    "# terme d'attache aux données\n",
    "Dataloss = []\n",
    "for k in range(N):\n",
    "    VT = x[k]\n",
    "    nk = VT.shape[0]\n",
    "    FT = torch.tensor(np.array([np.arange(nk-1),np.arange(1,nk)]).T).contiguous()\n",
    "    loss = lossVarifoldCurve(FS, VT, FT, Kw)\n",
    "    Dataloss.append(loss)\n",
    "    \n",
    "# fonction globale à minimiser\n",
    "loss = AtlasLDDMMloss2(Kv,Dataloss, gamma=0.1)\n",
    "\n",
    "nc = 7\n",
    "\n",
    "# initialisation des vecteurs moments p0\n",
    "p0 = []\n",
    "for k in range(N):\n",
    "    p0.append(torch.zeros(nc, 2, requires_grad=True))\n",
    "\n",
    "# initialisation des points de controle c\n",
    "c = torch.rand(nc,2, requires_grad=True)\n",
    "    \n",
    "# optimisation de p0 et xbar\n",
    "res = Optimize(loss,[*p0,xbar,c],niter=10)\n",
    "p0 = res[:-2]\n",
    "xbar = res[-2]\n",
    "c = res[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x) # N=20\n",
    "for k in range(4):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    #plt.plot(xbar.detach()[:,0],xbar.detach()[:,1],\"*b\")\n",
    "    #plt.plot(x[k][:,0],x[k][:,1],\"*k\")\n",
    "    plotfun = PlotRes2D(x[k])\n",
    "    plotfun(c,p0[k],Kv)\n",
    "    plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Données réelles - attache aux données de type mesures\n",
    "\n",
    "Pour terminer nous allons réaliser une étude avec des données de type nuages de points non ordonnés (obtenus ici par un simple seuillage \n",
    "des pixels sur les images de chiffres manuscrits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('trois.pt')\n",
    "\n",
    "for k in range(20):\n",
    "    plt.subplot(5,4,k+1)\n",
    "    plt.plot(x[k][:,0],x[k][:,1],\"*\")\n",
    "    plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8__ : Recommencer l'étude (construction d'atlas et ACP) avec les données du fichier `trois.pt`, en utilisant la fonction `lossmeas` fournie pour calculer les nouvelles fonctionnelles $A_k$. \n",
    "\n",
    "N.B. Pour les paramètres on pourra choisir $\\sigma_V=0.25$, $\\sigma_W=0.1$, $\\gamma=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8\n",
    "\n",
    "\n",
    "# définition des points xbar\n",
    "xbar = x[5].clone().detach().requires_grad_(True)\n",
    "\n",
    "# définition du noyau Kv\n",
    "Kv = GaussKernel(sigma=.25)\n",
    "\n",
    "# définition du noyau Kw\n",
    "Kw = GaussKernel(sigma=.1)\n",
    "\n",
    "# terme d'attache aux données\n",
    "Dataloss = []\n",
    "N = 20\n",
    "for k in range(N):\n",
    "    loss = lossmeas(x[k], Kw)\n",
    "    Dataloss.append(loss)\n",
    "\n",
    "# fonction globale à minimiser\n",
    "loss = AtlasLDDMMloss(Kv,Dataloss, gamma=0.1)\n",
    "\n",
    "# initialisation des vecteurs moments p0\n",
    "p0 = []\n",
    "for k in range(N):\n",
    "    p0.append(torch.zeros(xbar.shape, requires_grad=True))\n",
    "\n",
    "# optimisation de p0 et xbar\n",
    "res = Optimize(loss,[*p0,xbar],niter=10)\n",
    "p0 = res[:-1]\n",
    "xbar = res[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x) # N=20\n",
    "plt.figure(figsize=(16,20))\n",
    "for k in range(N):\n",
    "    plt.subplot(5,4,k+1)\n",
    "    plt.plot(x[k][:,0],x[k][:,1],\"k*\")\n",
    "    plt.plot(xbar.detach()[:,0],xbar.detach()[:,1],\"b*\")\n",
    "    p,q = Shooting(p0[k],xbar,Kv)\n",
    "    plt.plot(q.detach()[:,0],q.detach()[:,1],\"r*\")\n",
    "    plt.axis([0,1,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
